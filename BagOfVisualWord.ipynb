{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "jFYTOn6VhNKr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#The code chunk downloads and unzips the required data  \n",
        "\n",
        "import urllib.request\n",
        "import zipfile\n",
        "\n",
        "url = 'http://madm.dfki.de/files/sentinel/EuroSAT.zip'\n",
        "urllib.request.urlretrieve(url,\"2750.zip\")\n",
        "zf = zipfile.ZipFile(\"2750.zip\")\n",
        "zf.extractall()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cM94gNDCpISw",
        "colab_type": "code",
        "outputId": "14aa929b-db0e-43cc-d797-808ec57e60e3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "pip uninstall opencv-python"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[33mWARNING: Skipping opencv-python as it is not installed.\u001b[0m\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D0_4-Q_ZpTRH",
        "colab_type": "code",
        "outputId": "2470618a-afd8-41a3-87ed-1e8bd43bab6d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "pip install opencv-contrib-python==3.4.2.16"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: opencv-contrib-python==3.4.2.16 in /usr/local/lib/python3.6/dist-packages (3.4.2.16)\n",
            "Requirement already satisfied: numpy>=1.11.3 in /usr/local/lib/python3.6/dist-packages (from opencv-contrib-python==3.4.2.16) (1.18.4)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uSWjT6cPltkl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import cv2\n",
        "import numpy as np\n",
        "import os\n",
        "import shutil\n",
        "import random\n",
        "from pathlib import Path\n",
        "from sklearn.model_selection import train_test_split\n",
        "from scipy import ndimage\n",
        "from scipy.spatial import distance\n",
        "from sklearn.cluster import KMeans"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "847bda9ymFDE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from fastai.vision import *\n",
        "from fastai.metrics import error_rate\n",
        "\n",
        "data_path= os.getcwd()\n",
        "path= datapath4file(data_path+'/2750')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZCda2KXPpE5W",
        "colab_type": "code",
        "outputId": "97006759-d107-48d4-d58b-7924615b2baa",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "print(path)"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/2750\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4dKdyckFp63h",
        "colab_type": "code",
        "outputId": "281369e5-c7f4-4a37-c665-77bbcdf99b46",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "root_dir = path\n",
        "print(root_dir)"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/2750\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sYfeti6ZLBd9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "classes_dir = ['AnnualCrop', 'Forest', 'HerbaceousVegetation', 'Highway', 'Industrial', 'Pasture', 'PermanentCrop', 'Residential', 'River', 'SeaLake']\n",
        "test_ratio = 0.20"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cYFftykwLD72",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#remove already existing train and test folder (if any)\n",
        "\n",
        "if os.path.exists(root_dir / 'train'):\n",
        "  shutil.rmtree(root_dir / 'train', ignore_errors=False, onerror=None)\n",
        "\n",
        "if os.path.exists(root_dir / 'test'):\n",
        "  shutil.rmtree(root_dir / 'test', ignore_errors=False, onerror=None)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3VcP2PziLEvX",
        "colab_type": "code",
        "outputId": "23d1ab68-af55-4ccc-fff0-57272f2a2aac",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 527
        }
      },
      "source": [
        "for cls in classes_dir:\n",
        "    os.makedirs(root_dir / 'train' / cls)\n",
        "    os.makedirs(root_dir / 'test' / cls)\n",
        "\n",
        "\n",
        "    # Creating partitions of the data after shuffeling\n",
        "    src = root_dir / cls # Folder to copy images from\n",
        "\n",
        "    allFileNames = os.listdir(src)\n",
        "    np.random.shuffle(allFileNames)\n",
        "    train_FileNames, test_FileNames = np.split(np.array(allFileNames),\n",
        "                                                              [int(len(allFileNames)* (1 - test_ratio))])\n",
        "\n",
        "\n",
        "    train_FileNames = [src / name for name in train_FileNames.tolist()]\n",
        "    test_FileNames = [src / name for name in test_FileNames.tolist()]\n",
        "\n",
        "    print('Total images: ', len(allFileNames))\n",
        "    print('Training: ', len(train_FileNames))\n",
        "    print('Testing: ', len(test_FileNames))\n",
        "\n",
        "    # Copy-pasting images\n",
        "    for name in train_FileNames:\n",
        "        shutil.copy(name, root_dir / 'train' / cls)\n",
        "\n",
        "    for name in test_FileNames:\n",
        "        shutil.copy(name, root_dir / 'test' / cls)"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Total images:  3000\n",
            "Training:  2400\n",
            "Testing:  600\n",
            "Total images:  3000\n",
            "Training:  2400\n",
            "Testing:  600\n",
            "Total images:  3000\n",
            "Training:  2400\n",
            "Testing:  600\n",
            "Total images:  2500\n",
            "Training:  2000\n",
            "Testing:  500\n",
            "Total images:  2500\n",
            "Training:  2000\n",
            "Testing:  500\n",
            "Total images:  2000\n",
            "Training:  1600\n",
            "Testing:  400\n",
            "Total images:  2500\n",
            "Training:  2000\n",
            "Testing:  500\n",
            "Total images:  3000\n",
            "Training:  2400\n",
            "Testing:  600\n",
            "Total images:  2500\n",
            "Training:  2000\n",
            "Testing:  500\n",
            "Total images:  3000\n",
            "Training:  2400\n",
            "Testing:  600\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6uu3iPUoLKu-",
        "colab_type": "code",
        "outputId": "9ba9cb7b-dcba-4782-f874-160d1f0a59da",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 187
        }
      },
      "source": [
        "train_path = root_dir/'train'\n",
        "training_names = os.listdir(train_path)\n",
        "training_names\n",
        "# print(train_path)"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['Pasture',\n",
              " 'Residential',\n",
              " 'AnnualCrop',\n",
              " 'Highway',\n",
              " 'PermanentCrop',\n",
              " 'SeaLake',\n",
              " 'Forest',\n",
              " 'River',\n",
              " 'Industrial',\n",
              " 'HerbaceousVegetation']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6floa_3AWGfc",
        "colab_type": "code",
        "outputId": "38ac4951-2c9a-41b2-8200-ad3fb625c153",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "test_path = root_dir/'test'\n",
        "test_path = os.listdir(test_path)\n",
        "print(test_path)"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['Pasture', 'Residential', 'AnnualCrop', 'Highway', 'PermanentCrop', 'SeaLake', 'Forest', 'River', 'Industrial', 'HerbaceousVegetation']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7DXK1wDeLM6j",
        "colab_type": "code",
        "outputId": "70222db0-b05f-40a2-f617-3e0c1236e0e5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 187
        }
      },
      "source": [
        "test_path"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['Pasture',\n",
              " 'Residential',\n",
              " 'AnnualCrop',\n",
              " 'Highway',\n",
              " 'PermanentCrop',\n",
              " 'SeaLake',\n",
              " 'Forest',\n",
              " 'River',\n",
              " 'Industrial',\n",
              " 'HerbaceousVegetation']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ylP3drucLOFe",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# takes all images and convert them to grayscale. \n",
        "# return a dictionary that holds all images category by category. \n",
        "\n",
        "# def load_images_from_folder(folder):\n",
        "#     images = {}\n",
        "#     for filename in os.listdir(folder):\n",
        "#         category = []\n",
        "#         path = str(folder) + \"/\" + filename\n",
        "#         print(path)\n",
        "#         for cat in os.listdir(path):\n",
        "#             img = cv2.imread(str(path) + \"/\" + cat,0)\n",
        "#             if img is not None:\n",
        "#               print(\"done\")\n",
        "#               #cv2.imwrite(\"/content/2750/result.jpg\", img)\n",
        "#             break\n",
        "#     return images\n",
        "\n",
        "def load_images_from_folder(folder):\n",
        "    images = {}\n",
        "    for filename in os.listdir(folder):\n",
        "        category = []\n",
        "        path = str(folder) + \"/\" + filename\n",
        "        for cat in os.listdir(path):\n",
        "            img = cv2.imread(str(path) + \"/\" + cat,0)\n",
        "            #img = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
        "            if img is not None:\n",
        "                category.append(img)\n",
        "        images[filename] = category\n",
        "    return images\n",
        "\n",
        "images = load_images_from_folder(root_dir/'train')  # take all images category by category \n",
        "test = load_images_from_folder(root_dir/'test') # take test images "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XpRDGAjgLaxp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Creates descriptors using sift \n",
        "# Takes one parameter that is images dictionary\n",
        "# Return an array whose first index holds the decriptor_list without an order\n",
        "# And the second index holds the sift_vectors dictionary which holds the descriptors but this is seperated class by class\n",
        "def sift_features(images):\n",
        "    sift_vectors = {}\n",
        "    descriptor_list = []\n",
        "    sift = cv2.xfeatures2d.SIFT_create()\n",
        "    for key,value in images.items():\n",
        "        features = []\n",
        "        for img in value:\n",
        "            kp, des = sift.detectAndCompute(img,None)\n",
        "            if des is not None:\n",
        "              descriptor_list.extend(des)\n",
        "              features.append(des)\n",
        "        sift_vectors[key] = features\n",
        "    return [descriptor_list, sift_vectors]\n",
        "\n",
        "sifts = sift_features(images) \n",
        "# Takes the descriptor list which is unordered one\n",
        "descriptor_list = sifts[0] \n",
        "# Takes the sift features that is seperated class by class for train data\n",
        "all_bovw_feature = sifts[1] \n",
        "# Takes the sift features that is seperated class by class for test data\n",
        "test_bovw_feature = sift_features(test)[1] "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7HYNkxyOwgR4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# A k-means clustering algorithm who takes 2 parameter which is number \n",
        "# of cluster(k) and the other is descriptors list(unordered 1d array)\n",
        "# Returns an array that holds central points.\n",
        "def kmeans(k, descriptor_list):\n",
        "    kmeans = KMeans(n_clusters = k, n_init=10)\n",
        "    kmeans.fit(descriptor_list)\n",
        "    visual_words = kmeans.cluster_centers_ \n",
        "    return visual_words\n",
        "    \n",
        "# Takes the central points which is visual words    \n",
        "visual_words = kmeans(150, descriptor_list) "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EW_z0EfRC0uk",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        },
        "outputId": "d26c1bbd-9cd5-4f99-98f5-dd38d8537b17"
      },
      "source": [
        "pip install pyyaml h5py"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.6/dist-packages (3.13)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.6/dist-packages (2.10.0)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from h5py) (1.12.0)\n",
            "Requirement already satisfied: numpy>=1.7 in /usr/local/lib/python3.6/dist-packages (from h5py) (1.18.4)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a30sUKSjwlQr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# from tensorflow.keras.models import load_model\n",
        "\n",
        "# kmeans.save('my_model1.h5')  # creates a HDF5 file 'my_model.h5'\n",
        "\n",
        "# #kmeans = load_model('my_model1')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ag6iwd2KF_3m",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Takes 2 parameters. The first one is a dictionary that holds the descriptors that are separated class by class \n",
        "# And the second parameter is an array that holds the central points (visual words) of the k means clustering\n",
        "# Returns a dictionary that holds the histograms for each images that are separated class by class. \n",
        "\n",
        "def find_index(image, center):\n",
        "    count = 0\n",
        "    ind = 0\n",
        "    for i in range(len(center)):\n",
        "        if(i == 0):\n",
        "           count = distance.euclidean(image, center[i]) \n",
        "           #count = L1_dist(image, center[i])\n",
        "        else:\n",
        "            dist = distance.euclidean(image, center[i]) \n",
        "            #dist = L1_dist(image, center[i])\n",
        "            if(dist < count):\n",
        "                ind = i\n",
        "                count = dist\n",
        "    return ind\n",
        "\n",
        "def image_class(all_bovw, centers):\n",
        "    dict_feature = {}\n",
        "    for key,value in all_bovw.items():\n",
        "        category = []\n",
        "        for img in value:\n",
        "            histogram = np.zeros(len(centers))\n",
        "            for each_feature in img:\n",
        "                ind = find_index(each_feature, centers)\n",
        "                histogram[ind] += 1\n",
        "            category.append(histogram)\n",
        "        dict_feature[key] = category\n",
        "    return dict_feature\n",
        "    \n",
        "# Creates histograms for train data    \n",
        "bovw_train = image_class(all_bovw_feature, visual_words) \n",
        "# Creates histograms for test data\n",
        "bovw_test = image_class(test_bovw_feature, visual_words) \n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MXDdY2SBMZYa",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# 1-NN algorithm. We use this for predict the class of test images.\n",
        "# Takes 2 parameters. images is the feature vectors of train images and tests is the feature vectors of test images\n",
        "# Returns an array that holds number of test images, number of correctly predicted images and records of class based images respectively\n",
        "def knn(images, tests):\n",
        "    num_test = 0\n",
        "    correct_predict = 0\n",
        "    class_based = {}\n",
        "    \n",
        "    for test_key, test_val in tests.items():\n",
        "        class_based[test_key] = [0, 0] # [correct, all]\n",
        "        for tst in test_val:\n",
        "            predict_start = 0\n",
        "            #print(test_key)\n",
        "            minimum = 0\n",
        "            key = \"a\" #predicted\n",
        "            for train_key, train_val in images.items():\n",
        "                for train in train_val:\n",
        "                    if(predict_start == 0):\n",
        "                        minimum = distance.euclidean(tst, train)\n",
        "                        #minimum = L1_dist(tst,train)\n",
        "                        key = train_key\n",
        "                        predict_start += 1\n",
        "                    else:\n",
        "                        dist = distance.euclidean(tst, train)\n",
        "                        #dist = L1_dist(tst,train)\n",
        "                        if(dist < minimum):\n",
        "                            minimum = dist\n",
        "                            key = train_key\n",
        "            \n",
        "            if(test_key == key):\n",
        "                correct_predict += 1\n",
        "                class_based[test_key][0] += 1\n",
        "            num_test += 1\n",
        "            class_based[test_key][1] += 1\n",
        "            #print(minimum)\n",
        "    return [num_test, correct_predict, class_based]\n",
        "    \n",
        "# Call the knn function    \n",
        "results_bowl = knn(bovw_train, bovw_test) \n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PGJjtqa5O6_X",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 255
        },
        "outputId": "8f90b85e-60a7-4dcd-f87f-2b056b04bd76"
      },
      "source": [
        "# Calculates the average accuracy and class based accuracies.  \n",
        "def accuracy(results):\n",
        "    avg_accuracy = (results[1] / results[0]) * 100\n",
        "    print(\"Average accuracy: %\" + str(avg_accuracy))\n",
        "    print(\"\\nClass based accuracies: \\n\")\n",
        "    for key,value in results[2].items():\n",
        "        acc = (value[0] / value[1]) * 100\n",
        "        print(key + \" : %\" + str(acc))\n",
        "        \n",
        "# Calculates the accuracies and write the results to the console.       \n",
        "accuracy(results_bowl) "
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Average accuracy: %34.261407579273005\n",
            "\n",
            "Class based accuracies: \n",
            "\n",
            "Pasture : %70.11494252873564\n",
            "Residential : %56.02716468590832\n",
            "AnnualCrop : %60.338345864661655\n",
            "Highway : %29.183673469387756\n",
            "PermanentCrop : %13.114754098360656\n",
            "SeaLake : %3.125\n",
            "Forest : %1.8181818181818181\n",
            "River : %18.01801801801802\n",
            "Industrial : %28.4\n",
            "HerbaceousVegetation : %13.815789473684212\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}