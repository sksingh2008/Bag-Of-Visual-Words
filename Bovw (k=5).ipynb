{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyNbz5XA1XtwQbC9FAk+Zn+E"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "jFYTOn6VhNKr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#The code chunk downloads and unzips the required data  \n",
        "\n",
        "import urllib.request\n",
        "import zipfile\n",
        "\n",
        "url = 'http://madm.dfki.de/files/sentinel/EuroSAT.zip'\n",
        "urllib.request.urlretrieve(url,\"2750.zip\")\n",
        "zf = zipfile.ZipFile(\"2750.zip\")\n",
        "zf.extractall()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cM94gNDCpISw",
        "colab_type": "code",
        "outputId": "dc8179de-012f-4c56-f50a-9e176223e151",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "pip uninstall opencv-python"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[33mWARNING: Skipping opencv-python as it is not installed.\u001b[0m\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D0_4-Q_ZpTRH",
        "colab_type": "code",
        "outputId": "acc8285c-d805-4fcf-ee02-8fec4814fc78",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "pip install opencv-contrib-python==3.4.2.16"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: opencv-contrib-python==3.4.2.16 in /usr/local/lib/python3.6/dist-packages (3.4.2.16)\n",
            "Requirement already satisfied: numpy>=1.11.3 in /usr/local/lib/python3.6/dist-packages (from opencv-contrib-python==3.4.2.16) (1.18.4)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uSWjT6cPltkl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import cv2\n",
        "import numpy as np\n",
        "import os\n",
        "import shutil\n",
        "import random\n",
        "from pathlib import Path\n",
        "from sklearn.model_selection import train_test_split\n",
        "from scipy import ndimage\n",
        "from scipy.spatial import distance\n",
        "from sklearn.cluster import KMeans"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "847bda9ymFDE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from fastai.vision import *\n",
        "from fastai.metrics import error_rate\n",
        "\n",
        "data_path= os.getcwd()\n",
        "path= datapath4file(data_path+'/2750')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZCda2KXPpE5W",
        "colab_type": "code",
        "outputId": "30beb47e-db68-4339-9fa8-bf16c0e5bfb8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "print(path)"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/2750\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4dKdyckFp63h",
        "colab_type": "code",
        "outputId": "a7825234-e214-4f60-af07-5309d052fcfa",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "root_dir = path\n",
        "print(root_dir)"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/2750\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sYfeti6ZLBd9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "classes_dir = ['AnnualCrop', 'Forest', 'HerbaceousVegetation', 'Highway', 'Industrial', 'Pasture', 'PermanentCrop', 'Residential', 'River', 'SeaLake']\n",
        "test_ratio = 0.20"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cYFftykwLD72",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#remove already existing train and test folder (if any)\n",
        "\n",
        "if os.path.exists(root_dir / 'train'):\n",
        "  shutil.rmtree(root_dir / 'train', ignore_errors=False, onerror=None)\n",
        "\n",
        "if os.path.exists(root_dir / 'test'):\n",
        "  shutil.rmtree(root_dir / 'test', ignore_errors=False, onerror=None)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3VcP2PziLEvX",
        "colab_type": "code",
        "outputId": "9d0ccbe3-f5e9-433b-baad-ab7f0a81e090",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 527
        }
      },
      "source": [
        "for cls in classes_dir:\n",
        "    os.makedirs(root_dir / 'train' / cls)\n",
        "    os.makedirs(root_dir / 'test' / cls)\n",
        "\n",
        "\n",
        "    # Creating partitions of the data after shuffeling\n",
        "    src = root_dir / cls # Folder to copy images from\n",
        "\n",
        "    allFileNames = os.listdir(src)\n",
        "    np.random.shuffle(allFileNames)\n",
        "    train_FileNames, test_FileNames = np.split(np.array(allFileNames),\n",
        "                                                              [int(len(allFileNames)* (1 - test_ratio))])\n",
        "\n",
        "\n",
        "    train_FileNames = [src / name for name in train_FileNames.tolist()]\n",
        "    test_FileNames = [src / name for name in test_FileNames.tolist()]\n",
        "\n",
        "    print('Total images: ', len(allFileNames))\n",
        "    print('Training: ', len(train_FileNames))\n",
        "    print('Testing: ', len(test_FileNames))\n",
        "\n",
        "    # Copy-pasting images\n",
        "    for name in train_FileNames:\n",
        "        shutil.copy(name, root_dir / 'train' / cls)\n",
        "\n",
        "    for name in test_FileNames:\n",
        "        shutil.copy(name, root_dir / 'test' / cls)"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Total images:  3000\n",
            "Training:  2400\n",
            "Testing:  600\n",
            "Total images:  3000\n",
            "Training:  2400\n",
            "Testing:  600\n",
            "Total images:  3000\n",
            "Training:  2400\n",
            "Testing:  600\n",
            "Total images:  2500\n",
            "Training:  2000\n",
            "Testing:  500\n",
            "Total images:  2500\n",
            "Training:  2000\n",
            "Testing:  500\n",
            "Total images:  2000\n",
            "Training:  1600\n",
            "Testing:  400\n",
            "Total images:  2500\n",
            "Training:  2000\n",
            "Testing:  500\n",
            "Total images:  3000\n",
            "Training:  2400\n",
            "Testing:  600\n",
            "Total images:  2500\n",
            "Training:  2000\n",
            "Testing:  500\n",
            "Total images:  3000\n",
            "Training:  2400\n",
            "Testing:  600\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6uu3iPUoLKu-",
        "colab_type": "code",
        "outputId": "edb2eab5-e71d-494a-a3de-ff483be4f4bc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 187
        }
      },
      "source": [
        "train_path = root_dir/'train'\n",
        "training_names = os.listdir(train_path)\n",
        "training_names\n",
        "# print(train_path)"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['River',\n",
              " 'Forest',\n",
              " 'AnnualCrop',\n",
              " 'Industrial',\n",
              " 'SeaLake',\n",
              " 'Pasture',\n",
              " 'PermanentCrop',\n",
              " 'HerbaceousVegetation',\n",
              " 'Highway',\n",
              " 'Residential']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6floa_3AWGfc",
        "colab_type": "code",
        "outputId": "d132de68-6fad-48b6-86fd-e478f3ea2179",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "test_path = root_dir/'test'\n",
        "test_path = os.listdir(test_path)\n",
        "print(test_path)"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['River', 'Forest', 'AnnualCrop', 'Industrial', 'SeaLake', 'Pasture', 'PermanentCrop', 'HerbaceousVegetation', 'Highway', 'Residential']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7DXK1wDeLM6j",
        "colab_type": "code",
        "outputId": "642fbb46-43dc-4f02-f4c1-7ac879f1a145",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 187
        }
      },
      "source": [
        "test_path"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['River',\n",
              " 'Forest',\n",
              " 'AnnualCrop',\n",
              " 'Industrial',\n",
              " 'SeaLake',\n",
              " 'Pasture',\n",
              " 'PermanentCrop',\n",
              " 'HerbaceousVegetation',\n",
              " 'Highway',\n",
              " 'Residential']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ylP3drucLOFe",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# takes all images and convert them to grayscale. \n",
        "# return a dictionary that holds all images category by category. \n",
        "\n",
        "# def load_images_from_folder(folder):\n",
        "#     images = {}\n",
        "#     for filename in os.listdir(folder):\n",
        "#         category = []\n",
        "#         path = str(folder) + \"/\" + filename\n",
        "#         print(path)\n",
        "#         for cat in os.listdir(path):\n",
        "#             img = cv2.imread(str(path) + \"/\" + cat,0)\n",
        "#             if img is not None:\n",
        "#               print(\"done\")\n",
        "#               #cv2.imwrite(\"/content/2750/result.jpg\", img)\n",
        "#             break\n",
        "#     return images\n",
        "\n",
        "def load_images_from_folder(folder):\n",
        "    images = {}\n",
        "    for filename in os.listdir(folder):\n",
        "        category = []\n",
        "        path = str(folder) + \"/\" + filename\n",
        "        for cat in os.listdir(path):\n",
        "            img = cv2.imread(str(path) + \"/\" + cat,0)\n",
        "            #img = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
        "            if img is not None:\n",
        "                category.append(img)\n",
        "        images[filename] = category\n",
        "    return images\n",
        "\n",
        "images = load_images_from_folder(root_dir/'train')  # take all images category by category \n",
        "test = load_images_from_folder(root_dir/'test') # take test images "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XpRDGAjgLaxp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Creates descriptors using sift \n",
        "# Takes one parameter that is images dictionary\n",
        "# Return an array whose first index holds the decriptor_list without an order\n",
        "# And the second index holds the sift_vectors dictionary which holds the descriptors but this is seperated class by class\n",
        "def sift_features(images):\n",
        "    sift_vectors = {}\n",
        "    descriptor_list = []\n",
        "    sift = cv2.xfeatures2d.SIFT_create()\n",
        "    for key,value in images.items():\n",
        "        features = []\n",
        "        for img in value:\n",
        "            kp, des = sift.detectAndCompute(img,None)\n",
        "            if des is not None:\n",
        "              descriptor_list.extend(des)\n",
        "              features.append(des)\n",
        "        sift_vectors[key] = features\n",
        "    return [descriptor_list, sift_vectors]\n",
        "\n",
        "sifts = sift_features(images) \n",
        "# Takes the descriptor list which is unordered one\n",
        "descriptor_list = sifts[0] \n",
        "# Takes the sift features that is seperated class by class for train data\n",
        "all_bovw_feature = sifts[1] \n",
        "# Takes the sift features that is seperated class by class for test data\n",
        "test_bovw_feature = sift_features(test)[1] "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7HYNkxyOwgR4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# A k-means clustering algorithm who takes 2 parameter which is number \n",
        "# of cluster(k) and the other is descriptors list(unordered 1d array)\n",
        "# Returns an array that holds central points.\n",
        "def kmeans(k, descriptor_list):\n",
        "    kmeans = KMeans(n_clusters = k, n_init=10)\n",
        "    kmeans.fit(descriptor_list)\n",
        "    visual_words = kmeans.cluster_centers_ \n",
        "    return visual_words\n",
        "    \n",
        "# Takes the central points which is visual words    \n",
        "visual_words = kmeans(5, descriptor_list) "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EW_z0EfRC0uk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#pip install pyyaml h5py"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a30sUKSjwlQr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# from tensorflow.keras.models import load_model\n",
        "\n",
        "# kmeans.save('my_model1.h5')  # creates a HDF5 file 'my_model.h5'\n",
        "\n",
        "# #kmeans = load_model('my_model1')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ag6iwd2KF_3m",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Takes 2 parameters. The first one is a dictionary that holds the descriptors that are separated class by class \n",
        "# And the second parameter is an array that holds the central points (visual words) of the k means clustering\n",
        "# Returns a dictionary that holds the histograms for each images that are separated class by class. \n",
        "\n",
        "def find_index(image, center):\n",
        "    count = 0\n",
        "    ind = 0\n",
        "    for i in range(len(center)):\n",
        "        if(i == 0):\n",
        "           count = distance.euclidean(image, center[i]) \n",
        "           #count = L1_dist(image, center[i])\n",
        "        else:\n",
        "            dist = distance.euclidean(image, center[i]) \n",
        "            #dist = L1_dist(image, center[i])\n",
        "            if(dist < count):\n",
        "                ind = i\n",
        "                count = dist\n",
        "    return ind\n",
        "\n",
        "def image_class(all_bovw, centers):\n",
        "    dict_feature = {}\n",
        "    for key,value in all_bovw.items():\n",
        "        category = []\n",
        "        for img in value:\n",
        "            histogram = np.zeros(len(centers))\n",
        "            for each_feature in img:\n",
        "                ind = find_index(each_feature, centers)\n",
        "                histogram[ind] += 1\n",
        "            category.append(histogram)\n",
        "        dict_feature[key] = category\n",
        "    return dict_feature\n",
        "    \n",
        "# Creates histograms for train data    \n",
        "bovw_train = image_class(all_bovw_feature, visual_words) \n",
        "# Creates histograms for test data\n",
        "bovw_test = image_class(test_bovw_feature, visual_words) \n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MXDdY2SBMZYa",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# 1-NN algorithm. We use this for predict the class of test images.\n",
        "# Takes 2 parameters. images is the feature vectors of train images and tests is the feature vectors of test images\n",
        "# Returns an array that holds number of test images, number of correctly predicted images and records of class based images respectively\n",
        "def knn(images, tests):\n",
        "    num_test = 0\n",
        "    correct_predict = 0\n",
        "    class_based = {}\n",
        "    \n",
        "    for test_key, test_val in tests.items():\n",
        "        class_based[test_key] = [0, 0] # [correct, all]\n",
        "        for tst in test_val:\n",
        "            predict_start = 0\n",
        "            #print(test_key)\n",
        "            minimum = 0\n",
        "            key = \"a\" #predicted\n",
        "            for train_key, train_val in images.items():\n",
        "                for train in train_val:\n",
        "                    if(predict_start == 0):\n",
        "                        minimum = distance.euclidean(tst, train)\n",
        "                        #minimum = L1_dist(tst,train)\n",
        "                        key = train_key\n",
        "                        predict_start += 1\n",
        "                    else:\n",
        "                        dist = distance.euclidean(tst, train)\n",
        "                        #dist = L1_dist(tst,train)\n",
        "                        if(dist < minimum):\n",
        "                            minimum = dist\n",
        "                            key = train_key\n",
        "            \n",
        "            if(test_key == key):\n",
        "                correct_predict += 1\n",
        "                class_based[test_key][0] += 1\n",
        "            num_test += 1\n",
        "            class_based[test_key][1] += 1\n",
        "            #print(minimum)\n",
        "    return [num_test, correct_predict, class_based]\n",
        "    \n",
        "# Call the knn function    \n",
        "results_bowl = knn(bovw_train, bovw_test) \n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PGJjtqa5O6_X",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 255
        },
        "outputId": "75f4d5be-7283-47ae-bdbb-7bf16d5d1b03"
      },
      "source": [
        "# Calculates the average accuracy and class based accuracies.  \n",
        "def accuracy(results):\n",
        "    avg_accuracy = (results[1] / results[0]) * 100\n",
        "    print(\"Average accuracy: %\" + str(avg_accuracy))\n",
        "    print(\"\\nClass based accuracies: \\n\")\n",
        "    for key,value in results[2].items():\n",
        "        acc = (value[0] / value[1]) * 100\n",
        "        print(key + \" : %\" + str(acc))\n",
        "        \n",
        "# Calculates the accuracies and write the results to the console.       \n",
        "accuracy(results_bowl) "
      ],
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Average accuracy: %34.50487429451001\n",
            "\n",
            "Class based accuracies: \n",
            "\n",
            "River : %51.369863013698634\n",
            "Forest : %0.0\n",
            "AnnualCrop : %29.853479853479854\n",
            "Industrial : %66.4\n",
            "SeaLake : %0.0\n",
            "Pasture : %5.928853754940711\n",
            "PermanentCrop : %22.587268993839835\n",
            "HerbaceousVegetation : %15.698924731182796\n",
            "Highway : %16.768916155419223\n",
            "Residential : %58.87372013651877\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LRComTIRSL9Z",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}